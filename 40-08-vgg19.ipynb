{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7edb5d",
   "metadata": {
    "papermill": {
     "duration": 0.003183,
     "end_time": "2025-02-14T19:44:41.296956",
     "exception": false,
     "start_time": "2025-02-14T19:44:41.293773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VGG19 Multi-Task Model for MedMNIST Submission Using Kaggle Input Data (64×64 Resolution)\n",
    "\n",
    "This notebook loads MedMNIST datasets directly from the Kaggle input folder, converts the images (originally 28×28) to 3 channels and resizes them to 64×64 (to reduce memory usage), builds a VGG19-based model for each MedMNIST task (excluding ChestMNIST), trains each model for up to **100 epochs** with early stopping (monitoring validation loss), and generates a submission CSV file.  \n",
    "The submission file is formatted with columns: `id`, `id_image_in_task`, `task_name`, and `label`.\n",
    "\n",
    "*Note: The correct Python class for the dermatoscope images is `DermaMNIST` (with a capital M).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e62bfc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-14T19:44:41.303841Z",
     "iopub.status.busy": "2025-02-14T19:44:41.303480Z",
     "iopub.status.idle": "2025-02-14T19:44:54.304310Z",
     "shell.execute_reply": "2025-02-14T19:44:54.303123Z"
    },
    "papermill": {
     "duration": 13.00648,
     "end_time": "2025-02-14T19:44:54.306364",
     "exception": false,
     "start_time": "2025-02-14T19:44:41.299884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs found and configured: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for available GPUs and enable memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPUs found and configured:\", gpus)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found. Please set your runtime to GPU in the Kaggle Notebook settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b445346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:44:54.318325Z",
     "iopub.status.busy": "2025-02-14T19:44:54.317788Z",
     "iopub.status.idle": "2025-02-14T19:45:05.443048Z",
     "shell.execute_reply": "2025-02-14T19:45:05.442325Z"
    },
    "papermill": {
     "duration": 11.13119,
     "end_time": "2025-02-14T19:45:05.444704",
     "exception": false,
     "start_time": "2025-02-14T19:44:54.313514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q medmnist\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6124b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:45:05.451961Z",
     "iopub.status.busy": "2025-02-14T19:45:05.451447Z",
     "iopub.status.idle": "2025-02-14T19:45:05.457020Z",
     "shell.execute_reply": "2025-02-14T19:45:05.456217Z"
    },
    "papermill": {
     "duration": 0.01056,
     "end_time": "2025-02-14T19:45:05.458484",
     "exception": false,
     "start_time": "2025-02-14T19:45:05.447924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# Use 64×64 resolution for memory optimization\n",
    "TARGET_SIZE = (64, 64)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1facb6a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:45:05.465026Z",
     "iopub.status.busy": "2025-02-14T19:45:05.464814Z",
     "iopub.status.idle": "2025-02-14T19:45:05.471290Z",
     "shell.execute_reply": "2025-02-14T19:45:05.470613Z"
    },
    "papermill": {
     "duration": 0.011137,
     "end_time": "2025-02-14T19:45:05.472517",
     "exception": false,
     "start_time": "2025-02-14T19:45:05.461380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_npz_data(npz_path):\n",
    "    \"\"\"\n",
    "    Load train, val, and test arrays from a given .npz file.\n",
    "    Expected keys: 'train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels'\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    train_images = data['train_images']\n",
    "    train_labels = data['train_labels']\n",
    "    val_images = data['val_images']\n",
    "    val_labels = data['val_labels']\n",
    "    test_images = data['test_images']\n",
    "    test_labels = data['test_labels']\n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "\n",
    "def create_tf_dataset_from_numpy(images, labels, batch_size=BATCH_SIZE, augment=False):\n",
    "    \"\"\"\n",
    "    Convert numpy arrays to a tf.data.Dataset:\n",
    "      - Expand grayscale images (28×28) to (28,28,1) then tile to (28,28,3).\n",
    "      - Resize images to TARGET_SIZE (64×64).\n",
    "      - Normalize pixel values to [0,1].\n",
    "      - Optionally apply data augmentation.\n",
    "    \"\"\"\n",
    "    if images.ndim == 3:\n",
    "        images = np.expand_dims(images, axis=-1)  # (N,28,28,1)\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.tile(images, (1,1,1,3))         # (N,28,28,3)\n",
    "    \n",
    "    images = images.astype(np.float32) / 255.0\n",
    "    \n",
    "    def _process(image, label):\n",
    "        image = tf.image.resize(image, TARGET_SIZE)\n",
    "        if augment:\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_flip_up_down(image)\n",
    "            image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "            image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "        return image, label\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.map(_process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(buffer_size=len(images))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba189ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:45:05.479111Z",
     "iopub.status.busy": "2025-02-14T19:45:05.478908Z",
     "iopub.status.idle": "2025-02-14T19:45:14.798443Z",
     "shell.execute_reply": "2025-02-14T19:45:14.797481Z"
    },
    "papermill": {
     "duration": 9.325186,
     "end_time": "2025-02-14T19:45:14.800583",
     "exception": false,
     "start_time": "2025-02-14T19:45:05.475397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathmnist: 89996 train, 10004 val, 7180 test samples\n",
      "dermamnist: 7007 train, 1003 val, 2005 test samples\n",
      "octmnist: 97477 train, 10832 val, 1000 test samples\n",
      "pneumoniamnist: 4708 train, 524 val, 624 test samples\n",
      "retinamnist: 1080 train, 120 val, 400 test samples\n",
      "breastmnist: 546 train, 78 val, 156 test samples\n",
      "bloodmnist: 11959 train, 1712 val, 3421 test samples\n",
      "tissuemnist: 165466 train, 23640 val, 47280 test samples\n",
      "organamnist: 34581 train, 6491 val, 17778 test samples\n",
      "organcmnist: 13000 train, 2392 val, 8268 test samples\n",
      "organsmnist: 13940 train, 2452 val, 8829 test samples\n"
     ]
    }
   ],
   "source": [
    "# Define the list of tasks (excluding ChestMNIST)\n",
    "task_names = [\n",
    "    \"pathmnist\",\n",
    "    \"dermamnist\",  # Correct Python class is \"DermaMNIST\" as per INFO.\n",
    "    \"octmnist\",\n",
    "    \"pneumoniamnist\",\n",
    "    \"retinamnist\",\n",
    "    \"breastmnist\",\n",
    "    \"bloodmnist\",\n",
    "    \"tissuemnist\",\n",
    "    \"organamnist\",\n",
    "    \"organcmnist\",\n",
    "    \"organsmnist\"\n",
    "]\n",
    "\n",
    "# Use Kaggle input folder (no downloading)\n",
    "base_path = Path(\"/kaggle/input/tensor-reloaded-multi-task-med-mnist/data\")\n",
    "task_to_npz = {task: base_path / f\"{task}.npz\" for task in task_names}\n",
    "\n",
    "# Load datasets for each task\n",
    "train_datasets = {}\n",
    "val_datasets = {}\n",
    "test_datasets = {}\n",
    "\n",
    "for task in task_names:\n",
    "    (train_imgs, train_lbls), (val_imgs, val_lbls), (test_imgs, test_lbls) = load_npz_data(task_to_npz[task])\n",
    "    train_datasets[task] = (train_imgs, train_lbls)\n",
    "    val_datasets[task] = (val_imgs, val_lbls)\n",
    "    test_datasets[task] = (test_imgs, test_lbls)\n",
    "    print(f\"{task}: {len(train_imgs)} train, {len(val_imgs)} val, {len(test_imgs)} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca9d2dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:45:14.815008Z",
     "iopub.status.busy": "2025-02-14T19:45:14.814648Z",
     "iopub.status.idle": "2025-02-14T19:45:39.509929Z",
     "shell.execute_reply": "2025-02-14T19:45:39.509017Z"
    },
    "papermill": {
     "duration": 24.704131,
     "end_time": "2025-02-14T19:45:39.511346",
     "exception": false,
     "start_time": "2025-02-14T19:45:14.807215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathmnist: Test batches: 225\n",
      "dermamnist: Test batches: 63\n",
      "octmnist: Test batches: 32\n",
      "pneumoniamnist: Test batches: 20\n",
      "retinamnist: Test batches: 13\n",
      "breastmnist: Test batches: 5\n",
      "bloodmnist: Test batches: 107\n",
      "tissuemnist: Test batches: 1478\n",
      "organamnist: Test batches: 556\n",
      "organcmnist: Test batches: 259\n",
      "organsmnist: Test batches: 276\n"
     ]
    }
   ],
   "source": [
    "train_datasets_tf = {}\n",
    "val_datasets_tf = {}\n",
    "test_datasets_tf = {}\n",
    "\n",
    "for task in task_names:\n",
    "    train_imgs, train_lbls = train_datasets[task]\n",
    "    val_imgs, val_lbls = val_datasets[task]\n",
    "    test_imgs, test_lbls = test_datasets[task]\n",
    "    \n",
    "    train_datasets_tf[task] = create_tf_dataset_from_numpy(train_imgs, train_lbls, batch_size=BATCH_SIZE, augment=True)\n",
    "    val_datasets_tf[task]   = create_tf_dataset_from_numpy(val_imgs, val_lbls, batch_size=BATCH_SIZE, augment=False)\n",
    "    test_datasets_tf[task]  = create_tf_dataset_from_numpy(test_imgs, test_lbls, batch_size=BATCH_SIZE, augment=False)\n",
    "    \n",
    "    count = sum(1 for _ in test_datasets_tf[task])\n",
    "    print(f\"{task}: Test batches: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a63dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:45:39.519909Z",
     "iopub.status.busy": "2025-02-14T19:45:39.519654Z",
     "iopub.status.idle": "2025-02-14T19:45:39.524773Z",
     "shell.execute_reply": "2025-02-14T19:45:39.523978Z"
    },
    "papermill": {
     "duration": 0.010493,
     "end_time": "2025-02-14T19:45:39.525881",
     "exception": false,
     "start_time": "2025-02-14T19:45:39.515388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vgg19_model(num_classes, input_shape=(64,64,3)):\n",
    "    base_model = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model initially\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# (Optional testing)\n",
    "# num_classes = len(INFO[\"pathmnist\"]['label'])\n",
    "# vgg19_model = build_vgg19_model(num_classes, input_shape=(64,64,3))\n",
    "# vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aba819f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T19:45:39.533893Z",
     "iopub.status.busy": "2025-02-14T19:45:39.533660Z"
    },
    "papermill": {
     "duration": 2375.716192,
     "end_time": "2025-02-14T20:25:15.245800",
     "exception": false,
     "start_time": "2025-02-14T19:45:39.529608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training VGG19 model for pathmnist with 9 classes...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.5994 - loss: 1.1063 - val_accuracy: 0.7262 - val_loss: 0.7523\n",
      "Epoch 2/5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.6983 - loss: 0.8300 - val_accuracy: 0.7431 - val_loss: 0.6951\n",
      "Epoch 3/5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.7134 - loss: 0.7872 - val_accuracy: 0.7643 - val_loss: 0.6505\n",
      "Epoch 4/5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - accuracy: 0.7223 - loss: 0.7585 - val_accuracy: 0.7696 - val_loss: 0.6273\n",
      "Epoch 5/5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.7276 - loss: 0.7505 - val_accuracy: 0.7767 - val_loss: 0.6175\n",
      "\n",
      "Training VGG19 model for dermamnist with 7 classes...\n",
      "Epoch 1/5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.5772 - loss: 1.4869 - val_accuracy: 0.6869 - val_loss: 0.9087\n",
      "Epoch 2/5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6844 - loss: 0.9385 - val_accuracy: 0.6939 - val_loss: 0.8666\n",
      "Epoch 3/5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6813 - loss: 0.9250 - val_accuracy: 0.6959 - val_loss: 0.8565\n",
      "Epoch 4/5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6996 - loss: 0.8735 - val_accuracy: 0.7208 - val_loss: 0.8335\n",
      "Epoch 5/5\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6883 - loss: 0.8909 - val_accuracy: 0.7049 - val_loss: 0.8338\n",
      "\n",
      "Training VGG19 model for octmnist with 4 classes...\n",
      "Epoch 1/5\n",
      "\u001b[1m3047/3047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.6933 - loss: 0.8720 - val_accuracy: 0.7522 - val_loss: 0.7093\n",
      "Epoch 2/5\n",
      "\u001b[1m3047/3047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 12ms/step - accuracy: 0.7459 - loss: 0.7453 - val_accuracy: 0.7652 - val_loss: 0.6647\n",
      "Epoch 3/5\n",
      "\u001b[1m3047/3047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 12ms/step - accuracy: 0.7523 - loss: 0.7180 - val_accuracy: 0.7724 - val_loss: 0.6517\n",
      "Epoch 4/5\n",
      "\u001b[1m3047/3047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 12ms/step - accuracy: 0.7599 - loss: 0.6987 - val_accuracy: 0.7737 - val_loss: 0.6455\n",
      "Epoch 5/5\n",
      "\u001b[1m3047/3047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 12ms/step - accuracy: 0.7648 - loss: 0.6880 - val_accuracy: 0.7770 - val_loss: 0.6383\n",
      "\n",
      "Training VGG19 model for pneumoniamnist with 2 classes...\n",
      "Epoch 1/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.8244 - loss: 0.4093 - val_accuracy: 0.9103 - val_loss: 0.2036\n",
      "Epoch 2/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.2267 - val_accuracy: 0.9256 - val_loss: 0.1819\n",
      "Epoch 3/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9156 - loss: 0.1935 - val_accuracy: 0.8721 - val_loss: 0.2852\n",
      "Epoch 4/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9117 - loss: 0.2140 - val_accuracy: 0.9141 - val_loss: 0.1770\n",
      "Epoch 5/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9256 - loss: 0.1866 - val_accuracy: 0.9256 - val_loss: 0.1679\n",
      "\n",
      "Training VGG19 model for retinamnist with 5 classes...\n",
      "Epoch 1/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 131ms/step - accuracy: 0.4271 - loss: 1.6468 - val_accuracy: 0.4333 - val_loss: 1.3060\n",
      "Epoch 2/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4699 - loss: 1.3405 - val_accuracy: 0.4333 - val_loss: 1.2368\n",
      "Epoch 3/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4462 - loss: 1.3201 - val_accuracy: 0.4167 - val_loss: 1.2290\n",
      "Epoch 4/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4528 - loss: 1.2906 - val_accuracy: 0.4500 - val_loss: 1.2715\n",
      "Epoch 5/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4804 - loss: 1.2651 - val_accuracy: 0.4333 - val_loss: 1.2215\n",
      "\n",
      "Training VGG19 model for breastmnist with 2 classes...\n",
      "Epoch 1/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 298ms/step - accuracy: 0.5754 - loss: 1.1554 - val_accuracy: 0.7436 - val_loss: 0.5479\n",
      "Epoch 2/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6867 - loss: 0.6166 - val_accuracy: 0.7564 - val_loss: 0.5272\n",
      "Epoch 3/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7433 - loss: 0.5544 - val_accuracy: 0.7949 - val_loss: 0.4972\n",
      "Epoch 4/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7672 - loss: 0.5038 - val_accuracy: 0.8077 - val_loss: 0.4923\n",
      "Epoch 5/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.4357 - val_accuracy: 0.8077 - val_loss: 0.5008\n",
      "\n",
      "Training VGG19 model for bloodmnist with 8 classes...\n",
      "Epoch 1/5\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.5815 - loss: 1.1326 - val_accuracy: 0.7617 - val_loss: 0.6294\n",
      "Epoch 2/5\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7353 - loss: 0.7115 - val_accuracy: 0.7938 - val_loss: 0.5556\n",
      "Epoch 3/5\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7543 - loss: 0.6758 - val_accuracy: 0.7973 - val_loss: 0.5323\n",
      "Epoch 4/5\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7707 - loss: 0.6295 - val_accuracy: 0.8172 - val_loss: 0.4909\n",
      "Epoch 5/5\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7727 - loss: 0.6048 - val_accuracy: 0.8207 - val_loss: 0.4988\n",
      "\n",
      "Training VGG19 model for tissuemnist with 8 classes...\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "models = {}\n",
    "histories = {}\n",
    "\n",
    "for task in task_names:\n",
    "    num_classes = len(INFO[task]['label'])\n",
    "    print(f\"\\nTraining VGG19 model for {task} with {num_classes} classes...\")\n",
    "    model_task = build_vgg19_model(num_classes, input_shape=(64,64,3))\n",
    "    history = model_task.fit(\n",
    "        train_datasets_tf[task],\n",
    "        validation_data=val_datasets_tf[task],\n",
    "        epochs=5,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    models[task] = model_task\n",
    "    histories[task] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2625f",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-14T18:07:02.129Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_rows = []\n",
    "global_id = 0\n",
    "\n",
    "for task in task_names:\n",
    "    model_task = models[task]\n",
    "    preds_list = []\n",
    "    for images, _ in test_datasets_tf[task]:\n",
    "        preds = model_task.predict(images)\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        preds_list.append(preds)\n",
    "    preds_all = np.concatenate(preds_list)\n",
    "    for idx, pred in enumerate(preds_all):\n",
    "        submission_rows.append([global_id, idx, task, int(pred)])\n",
    "        global_id += 1\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows, columns=[\"id\", \"id_image_in_task\", \"task_name\", \"label\"])\n",
    "print(\"Total submission rows:\", len(submission_df))\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3ed05",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd30d1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6f459",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9915460,
     "sourceId": 86864,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2437.58347,
   "end_time": "2025-02-14T20:25:16.268166",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-14T19:44:38.684696",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
