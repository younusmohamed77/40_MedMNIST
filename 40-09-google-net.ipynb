{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a314037",
   "metadata": {
    "papermill": {
     "duration": 0.003627,
     "end_time": "2025-02-14T18:27:26.920133",
     "exception": false,
     "start_time": "2025-02-14T18:27:26.916506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# InceptionV3 Multi-Task Model for MedMNIST Submission Using Kaggle Input Data (299×299 Resolution)\n",
    "\n",
    "This notebook loads MedMNIST datasets directly from the Kaggle input folder, converts the images (originally 28×28 grayscale) to 3-channel format and resizes them to 75x75, builds an InceptionV3-based model for each MedMNIST task (excluding ChestMNIST), trains each model for up to **100 epochs** with early stopping (monitoring validation loss), and generates a submission CSV file with columns: `id`, `id_image_in_task`, `task_name`, and `label`.\n",
    "\n",
    "*Note: The correct Python class for the dermatoscope images is `DermaMNIST` (with a capital M).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f74b69",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-14T18:27:26.926914Z",
     "iopub.status.busy": "2025-02-14T18:27:26.926589Z",
     "iopub.status.idle": "2025-02-14T18:27:39.533594Z",
     "shell.execute_reply": "2025-02-14T18:27:39.532592Z"
    },
    "papermill": {
     "duration": 12.612013,
     "end_time": "2025-02-14T18:27:39.535075",
     "exception": false,
     "start_time": "2025-02-14T18:27:26.923062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs found and configured: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for available GPUs and enable dynamic memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPUs found and configured:\", gpus)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found. Please set your runtime to GPU in the Kaggle Notebook settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac403558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T18:27:39.542184Z",
     "iopub.status.busy": "2025-02-14T18:27:39.541726Z",
     "iopub.status.idle": "2025-02-14T18:27:50.357997Z",
     "shell.execute_reply": "2025-02-14T18:27:50.357269Z"
    },
    "papermill": {
     "duration": 10.821302,
     "end_time": "2025-02-14T18:27:50.359609",
     "exception": false,
     "start_time": "2025-02-14T18:27:39.538307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q medmnist \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score\n",
    "import medmnist\n",
    "from medmnist import INFO  # Contains metadata for each dataset\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8661fa2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T18:27:50.367208Z",
     "iopub.status.busy": "2025-02-14T18:27:50.366731Z",
     "iopub.status.idle": "2025-02-14T18:27:50.371922Z",
     "shell.execute_reply": "2025-02-14T18:27:50.371315Z"
    },
    "papermill": {
     "duration": 0.009992,
     "end_time": "2025-02-14T18:27:50.373045",
     "exception": false,
     "start_time": "2025-02-14T18:27:50.363053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# InceptionV3 requires a minimum size of 75x75; we set our target resolution to 75x75.\n",
    "TARGET_SIZE = (75, 75)\n",
    "BATCH_SIZE = 16  # Use a smaller batch size for memory efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6278702c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T18:27:50.379898Z",
     "iopub.status.busy": "2025-02-14T18:27:50.379669Z",
     "iopub.status.idle": "2025-02-14T18:27:50.386308Z",
     "shell.execute_reply": "2025-02-14T18:27:50.385516Z"
    },
    "papermill": {
     "duration": 0.011294,
     "end_time": "2025-02-14T18:27:50.387473",
     "exception": false,
     "start_time": "2025-02-14T18:27:50.376179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_npz_data(npz_path):\n",
    "    \"\"\"\n",
    "    Load train, val, and test arrays from a given .npz file.\n",
    "    Expected keys: 'train_images', 'train_labels', 'val_images', 'val_labels', 'test_images', 'test_labels'\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    train_images = data['train_images']\n",
    "    train_labels = data['train_labels']\n",
    "    val_images = data['val_images']\n",
    "    val_labels = data['val_labels']\n",
    "    test_images = data['test_images']\n",
    "    test_labels = data['test_labels']\n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "\n",
    "def create_tf_dataset_from_numpy(images, labels, batch_size=BATCH_SIZE, augment=False):\n",
    "    \"\"\"\n",
    "    Convert numpy arrays to a tf.data.Dataset:\n",
    "      - Expand grayscale images (28×28) to (28,28,1) then tile to (28,28,3).\n",
    "      - Resize images to TARGET_SIZE (75×75).\n",
    "      - Normalize pixel values to [0, 1].\n",
    "      - Optionally apply data augmentation.\n",
    "    \"\"\"\n",
    "    if images.ndim == 3:\n",
    "        images = np.expand_dims(images, axis=-1)  # (N,28,28,1)\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.tile(images, (1, 1, 1, 3))       # (N,28,28,3)\n",
    "    \n",
    "    images = images.astype(np.float32) / 255.0\n",
    "    \n",
    "    def _process(image, label):\n",
    "        image = tf.image.resize(image, TARGET_SIZE)\n",
    "        if augment:\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_flip_up_down(image)\n",
    "            image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "            image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "        return image, label\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.map(_process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(buffer_size=len(images))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6160b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T18:27:50.394231Z",
     "iopub.status.busy": "2025-02-14T18:27:50.394008Z",
     "iopub.status.idle": "2025-02-14T18:28:00.475135Z",
     "shell.execute_reply": "2025-02-14T18:28:00.474225Z"
    },
    "papermill": {
     "duration": 10.085969,
     "end_time": "2025-02-14T18:28:00.476513",
     "exception": false,
     "start_time": "2025-02-14T18:27:50.390544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathmnist: 89996 train, 10004 val, 7180 test samples\n",
      "dermamnist: 7007 train, 1003 val, 2005 test samples\n",
      "octmnist: 97477 train, 10832 val, 1000 test samples\n",
      "pneumoniamnist: 4708 train, 524 val, 624 test samples\n",
      "retinamnist: 1080 train, 120 val, 400 test samples\n",
      "breastmnist: 546 train, 78 val, 156 test samples\n",
      "bloodmnist: 11959 train, 1712 val, 3421 test samples\n",
      "tissuemnist: 165466 train, 23640 val, 47280 test samples\n",
      "organamnist: 34581 train, 6491 val, 17778 test samples\n",
      "organcmnist: 13000 train, 2392 val, 8268 test samples\n",
      "organsmnist: 13940 train, 2452 val, 8829 test samples\n"
     ]
    }
   ],
   "source": [
    "# Define the list of tasks (excluding ChestMNIST)\n",
    "task_names = [\n",
    "    \"pathmnist\",\n",
    "    \"dermamnist\",  # The MedMNIST INFO should have \"DermaMNIST\" as the python_class.\n",
    "    \"octmnist\",\n",
    "    \"pneumoniamnist\",\n",
    "    \"retinamnist\",\n",
    "    \"breastmnist\",\n",
    "    \"bloodmnist\",\n",
    "    \"tissuemnist\",\n",
    "    \"organamnist\",\n",
    "    \"organcmnist\",\n",
    "    \"organsmnist\"\n",
    "]\n",
    "\n",
    "# Use the Kaggle input folder\n",
    "base_path = Path(\"/kaggle/input/tensor-reloaded-multi-task-med-mnist/data\")\n",
    "task_to_npz = {task: base_path / f\"{task}.npz\" for task in task_names}\n",
    "\n",
    "# Load datasets for each task\n",
    "train_datasets = {}\n",
    "val_datasets = {}\n",
    "test_datasets = {}\n",
    "\n",
    "for task in task_names:\n",
    "    (train_imgs, train_lbls), (val_imgs, val_lbls), (test_imgs, test_lbls) = load_npz_data(task_to_npz[task])\n",
    "    train_datasets[task] = (train_imgs, train_lbls)\n",
    "    val_datasets[task] = (val_imgs, val_lbls)\n",
    "    test_datasets[task] = (test_imgs, test_lbls)\n",
    "    print(f\"{task}: {len(train_imgs)} train, {len(val_imgs)} val, {len(test_imgs)} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54241e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T18:28:00.484601Z",
     "iopub.status.busy": "2025-02-14T18:28:00.484374Z",
     "iopub.status.idle": "2025-02-14T18:28:27.648482Z",
     "shell.execute_reply": "2025-02-14T18:28:27.647435Z"
    },
    "papermill": {
     "duration": 27.169496,
     "end_time": "2025-02-14T18:28:27.649881",
     "exception": false,
     "start_time": "2025-02-14T18:28:00.480385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathmnist: Test batches: 449\n",
      "dermamnist: Test batches: 126\n",
      "octmnist: Test batches: 63\n",
      "pneumoniamnist: Test batches: 39\n",
      "retinamnist: Test batches: 25\n",
      "breastmnist: Test batches: 10\n",
      "bloodmnist: Test batches: 214\n",
      "tissuemnist: Test batches: 2955\n",
      "organamnist: Test batches: 1112\n",
      "organcmnist: Test batches: 517\n",
      "organsmnist: Test batches: 552\n"
     ]
    }
   ],
   "source": [
    "train_datasets_tf = {}\n",
    "val_datasets_tf = {}\n",
    "test_datasets_tf = {}\n",
    "\n",
    "for task in task_names:\n",
    "    train_imgs, train_lbls = train_datasets[task]\n",
    "    val_imgs, val_lbls = val_datasets[task]\n",
    "    test_imgs, test_lbls = test_datasets[task]\n",
    "    \n",
    "    train_datasets_tf[task] = create_tf_dataset_from_numpy(train_imgs, train_lbls, batch_size=BATCH_SIZE, augment=True)\n",
    "    val_datasets_tf[task]   = create_tf_dataset_from_numpy(val_imgs, val_lbls, batch_size=BATCH_SIZE, augment=False)\n",
    "    test_datasets_tf[task]  = create_tf_dataset_from_numpy(test_imgs, test_lbls, batch_size=BATCH_SIZE, augment=False)\n",
    "    \n",
    "    count = sum(1 for _ in test_datasets_tf[task])\n",
    "    print(f\"{task}: Test batches: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0079c1e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T18:28:27.659137Z",
     "iopub.status.busy": "2025-02-14T18:28:27.658868Z",
     "iopub.status.idle": "2025-02-14T18:28:27.663737Z",
     "shell.execute_reply": "2025-02-14T18:28:27.663131Z"
    },
    "papermill": {
     "duration": 0.010742,
     "end_time": "2025-02-14T18:28:27.664871",
     "exception": false,
     "start_time": "2025-02-14T18:28:27.654129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_inceptionv3_model(num_classes, input_shape=(75,75,3)):\n",
    "    base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model initially\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# (Optional testing)\n",
    "# num_classes = len(INFO[\"pathmnist\"]['label'])\n",
    "# inception_model = build_inceptionv3_model(num_classes, input_shape=(75,75,3))\n",
    "# inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e04e8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T18:28:27.673153Z",
     "iopub.status.busy": "2025-02-14T18:28:27.672906Z"
    },
    "papermill": {
     "duration": 2089.473169,
     "end_time": "2025-02-14T19:03:17.141849",
     "exception": false,
     "start_time": "2025-02-14T18:28:27.668680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training InceptionV3 model for pathmnist with 9 classes...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 18ms/step - accuracy: 0.6998 - loss: 0.8727 - val_accuracy: 0.7792 - val_loss: 0.6227\n",
      "Epoch 2/100\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 15ms/step - accuracy: 0.7565 - loss: 0.6943 - val_accuracy: 0.7925 - val_loss: 0.5989\n",
      "Epoch 3/100\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 15ms/step - accuracy: 0.7663 - loss: 0.6780 - val_accuracy: 0.7941 - val_loss: 0.5915\n",
      "Epoch 4/100\n",
      "\u001b[1m5625/5625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 15ms/step - accuracy: 0.7746 - loss: 0.6560 - val_accuracy: 0.7973 - val_loss: 0.5893\n",
      "Epoch 5/100\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "models = {}\n",
    "histories = {}\n",
    "\n",
    "for task in task_names:\n",
    "    num_classes = len(INFO[task]['label'])\n",
    "    print(f\"\\nTraining InceptionV3 model for {task} with {num_classes} classes...\")\n",
    "    model_task = build_inceptionv3_model(num_classes, input_shape=(75,75,3))\n",
    "    history = model_task.fit(\n",
    "        train_datasets_tf[task],\n",
    "        validation_data=val_datasets_tf[task],\n",
    "        epochs=100,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    models[task] = model_task\n",
    "    histories[task] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98370ee1",
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-14T18:27:04.876Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_rows = []\n",
    "global_id = 0\n",
    "\n",
    "for task in task_names:\n",
    "    model_task = models[task]\n",
    "    preds_list = []\n",
    "    for images, _ in test_datasets_tf[task]:\n",
    "        preds = model_task.predict(images)\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        preds_list.append(preds)\n",
    "    preds_all = np.concatenate(preds_list)\n",
    "    for idx, pred in enumerate(preds_all):\n",
    "        submission_rows.append([global_id, idx, task, int(pred)])\n",
    "        global_id += 1\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows, columns=[\"id\", \"id_image_in_task\", \"task_name\", \"label\"])\n",
    "print(\"Total submission rows:\", len(submission_df))\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233ec54",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6621b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc65cd8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8b7ac",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d39d5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fae0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9915460,
     "sourceId": 86864,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2153.862625,
   "end_time": "2025-02-14T19:03:18.161576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-14T18:27:24.298951",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
