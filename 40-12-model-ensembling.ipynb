{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e04d0f",
   "metadata": {
    "papermill": {
     "duration": 0.00268,
     "end_time": "2025-02-22T12:11:03.567089",
     "exception": false,
     "start_time": "2025-02-22T12:11:03.564409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weighted Ensemble for MedMNIST Multi‑Task Challenge\n",
    "This notebook implements a weighted ensemble of two pre‑trained MedMNIST multi‑task models. Instead of a simple average of their softmax outputs, we compute model weights (based on their validation scores) and use these weights to average the probabilities. The final predictions are used to generate a submission CSV file. This approach may boost performance by giving more influence to the better‐performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db91307b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T12:11:03.572719Z",
     "iopub.status.busy": "2025-02-22T12:11:03.572422Z",
     "iopub.status.idle": "2025-02-22T12:11:13.365608Z",
     "shell.execute_reply": "2025-02-22T12:11:13.364622Z"
    },
    "papermill": {
     "duration": 9.798196,
     "end_time": "2025-02-22T12:11:13.367788",
     "exception": false,
     "start_time": "2025-02-22T12:11:03.569592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q timm medmnist\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da49f3b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-22T12:11:13.374558Z",
     "iopub.status.busy": "2025-02-22T12:11:13.374312Z",
     "iopub.status.idle": "2025-02-22T12:11:26.427496Z",
     "shell.execute_reply": "2025-02-22T12:11:26.426699Z"
    },
    "papermill": {
     "duration": 13.057997,
     "end_time": "2025-02-22T12:11:26.428907",
     "exception": false,
     "start_time": "2025-02-22T12:11:13.370910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using :  cuda\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from medmnist import INFO\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using : \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2311117f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T12:11:26.435609Z",
     "iopub.status.busy": "2025-02-22T12:11:26.435348Z",
     "iopub.status.idle": "2025-02-22T12:11:26.445364Z",
     "shell.execute_reply": "2025-02-22T12:11:26.444529Z"
    },
    "papermill": {
     "duration": 0.014681,
     "end_time": "2025-02-22T12:11:26.446610",
     "exception": false,
     "start_time": "2025-02-22T12:11:26.431929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global list of tasks – must match your training order!\n",
    "DATASETS = [\n",
    "    'pathmnist',\n",
    "    'dermamnist',\n",
    "    'octmnist',\n",
    "    'pneumoniamnist',\n",
    "    'retinamnist',\n",
    "    'breastmnist',\n",
    "    'bloodmnist',\n",
    "    'tissuemnist',\n",
    "    'organamnist',\n",
    "    'organcmnist',\n",
    "    'organsmnist'\n",
    "]\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "        self.act = nn.GELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(x + self.block(x))\n",
    "\n",
    "class MedMNISTMultiTaskModel(nn.Module):\n",
    "    def __init__(self, backbone_name='convnext_tiny', pretrained=True, head_type='bottleneck', dropout_rate=0.2, stochastic_depth_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set the number of classes per task using MedMNIST INFO\n",
    "        self.task_outputs = {task: len(INFO[task]['label']) for task in DATASETS}\n",
    "\n",
    "        # Create backbone using timm (ConvNeXt in this example)\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            drop_path_rate=stochastic_depth_rate\n",
    "        )\n",
    "        # Adapt the stem for 28x28 images (3 channels)\n",
    "        self.backbone.stem[0] = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1)\n",
    "        feat_dim = self.backbone.num_features\n",
    "\n",
    "        # Create task-specific heads\n",
    "        self.heads = nn.ModuleDict()\n",
    "        for task, num_classes in self.task_outputs.items():\n",
    "            if head_type == 'bottleneck':\n",
    "                head = nn.Sequential(\n",
    "                    nn.LayerNorm(feat_dim),\n",
    "                    nn.Linear(feat_dim, feat_dim // 4),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                    nn.Linear(feat_dim // 4, num_classes)\n",
    "                )\n",
    "            else:\n",
    "                head = nn.Sequential(\n",
    "                    nn.LayerNorm(feat_dim),\n",
    "                    nn.Linear(feat_dim, num_classes)\n",
    "                )\n",
    "            self.heads[task] = head\n",
    "\n",
    "    def forward(self, x, task_ids=None):\n",
    "        features = self.backbone(x)  # shape: (B, feat_dim)\n",
    "        if task_ids is not None:\n",
    "            outputs = torch.zeros(x.size(0), max(self.task_outputs.values())).to(x.device)\n",
    "            for i, tid in enumerate(task_ids):\n",
    "                task_name = DATASETS[tid.item()]\n",
    "                num_cls = self.task_outputs[task_name]\n",
    "                out = self.heads[task_name](features[i:i+1])\n",
    "                outputs[i, :num_cls] = out.squeeze(0)\n",
    "            return outputs\n",
    "        else:\n",
    "            return {task: head(features) for task, head in self.heads.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba3f09c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T12:11:26.452639Z",
     "iopub.status.busy": "2025-02-22T12:11:26.452408Z",
     "iopub.status.idle": "2025-02-22T12:11:26.456169Z",
     "shell.execute_reply": "2025-02-22T12:11:26.455403Z"
    },
    "papermill": {
     "duration": 0.008043,
     "end_time": "2025-02-22T12:11:26.457346",
     "exception": false,
     "start_time": "2025-02-22T12:11:26.449303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model):\n",
    "    \"\"\"\n",
    "    Load checkpoint into the provided model (using strict=False).\n",
    "    Returns the model and its validation metric.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    missing, unexpected = model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    print(f\"Loaded checkpoint from epoch {checkpoint.get('epoch', -1)}; missing keys: {missing}, unexpected keys: {unexpected}\")\n",
    "    metric = checkpoint.get('best_f1', checkpoint.get('best_metric', 0.0))\n",
    "    return model, metric\n",
    "\n",
    "# Define paths for the two checkpoints (adjust these paths to your input folders)\n",
    "checkpoint_path1 = \"/kaggle/input/improving-accuracy-with-multihead-backbone/best_model.pth\"  \n",
    "checkpoint_path2 = \"/kaggle/input/fork-of-convnext-tiny-notebook8a8c996b9/best_model.pth\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3e955a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T12:11:26.463485Z",
     "iopub.status.busy": "2025-02-22T12:11:26.463272Z",
     "iopub.status.idle": "2025-02-22T12:11:29.222513Z",
     "shell.execute_reply": "2025-02-22T12:11:29.221358Z"
    },
    "papermill": {
     "duration": 2.763951,
     "end_time": "2025-02-22T12:11:29.223967",
     "exception": false,
     "start_time": "2025-02-22T12:11:26.460016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathmnist: 7180 test images, 29 batches\n",
      "dermamnist: 2005 test images, 8 batches\n",
      "octmnist: 1000 test images, 4 batches\n",
      "pneumoniamnist: 624 test images, 3 batches\n",
      "retinamnist: 400 test images, 2 batches\n",
      "breastmnist: 156 test images, 1 batches\n",
      "bloodmnist: 3421 test images, 14 batches\n",
      "tissuemnist: 47280 test images, 185 batches\n",
      "organamnist: 17778 test images, 70 batches\n",
      "organcmnist: 8268 test images, 33 batches\n",
      "organsmnist: 8829 test images, 35 batches\n"
     ]
    }
   ],
   "source": [
    "class MedMNISTTestDataset(Dataset):\n",
    "    def __init__(self, npz_path, transform=None):\n",
    "        data = np.load(npz_path)\n",
    "        self.images = data['test_images']  # shape: (N, 28, 28)\n",
    "        if self.images.ndim == 3:\n",
    "            self.images = np.expand_dims(self.images, axis=-1)\n",
    "        if self.images.shape[-1] == 1:\n",
    "            self.images = np.tile(self.images, (1, 1, 1, 3))\n",
    "        self.images = self.images.astype(np.float32) / 255.0\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Convert HWC to CHW\n",
    "        image = torch.tensor(image).permute(2, 0, 1)\n",
    "        return image\n",
    "        \n",
    "# Create test DataLoaders for each task\n",
    "test_dataloaders = {}\n",
    "base_path = Path(\"/kaggle/input/tensor-reloaded-multi-task-med-mnist/data\")\n",
    "for task in DATASETS:\n",
    "    npz_path = base_path / f\"{task}.npz\"\n",
    "    dataset = MedMNISTTestDataset(npz_path)\n",
    "    loader = DataLoader(dataset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_dataloaders[task] = loader\n",
    "    print(f\"{task}: {len(dataset)} test images, {len(loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4665261a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T12:11:29.231779Z",
     "iopub.status.busy": "2025-02-22T12:11:29.231533Z",
     "iopub.status.idle": "2025-02-22T12:11:45.241021Z",
     "shell.execute_reply": "2025-02-22T12:11:45.240005Z"
    },
    "papermill": {
     "duration": 16.01502,
     "end_time": "2025-02-22T12:11:45.242617",
     "exception": false,
     "start_time": "2025-02-22T12:11:29.227597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2013e823fc641648c7361dfb0de31ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-837839080bf8>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 30; missing keys: ['heads.pathmnist.1.weight', 'heads.pathmnist.1.bias', 'heads.pathmnist.4.weight', 'heads.pathmnist.4.bias', 'heads.dermamnist.1.weight', 'heads.dermamnist.1.bias', 'heads.dermamnist.4.weight', 'heads.dermamnist.4.bias', 'heads.octmnist.1.weight', 'heads.octmnist.1.bias', 'heads.octmnist.4.weight', 'heads.octmnist.4.bias', 'heads.pneumoniamnist.1.weight', 'heads.pneumoniamnist.1.bias', 'heads.pneumoniamnist.4.weight', 'heads.pneumoniamnist.4.bias', 'heads.retinamnist.1.weight', 'heads.retinamnist.1.bias', 'heads.retinamnist.4.weight', 'heads.retinamnist.4.bias', 'heads.breastmnist.1.weight', 'heads.breastmnist.1.bias', 'heads.breastmnist.4.weight', 'heads.breastmnist.4.bias', 'heads.bloodmnist.1.weight', 'heads.bloodmnist.1.bias', 'heads.bloodmnist.4.weight', 'heads.bloodmnist.4.bias', 'heads.tissuemnist.1.weight', 'heads.tissuemnist.1.bias', 'heads.tissuemnist.4.weight', 'heads.tissuemnist.4.bias', 'heads.organamnist.1.weight', 'heads.organamnist.1.bias', 'heads.organamnist.4.weight', 'heads.organamnist.4.bias', 'heads.organcmnist.1.weight', 'heads.organcmnist.1.bias', 'heads.organcmnist.4.weight', 'heads.organcmnist.4.bias', 'heads.organsmnist.1.weight', 'heads.organsmnist.1.bias', 'heads.organsmnist.4.weight', 'heads.organsmnist.4.bias'], unexpected keys: ['heads.pathmnist.1.0.weight', 'heads.pathmnist.1.0.bias', 'heads.pathmnist.1.3.0.weight', 'heads.pathmnist.1.3.0.bias', 'heads.pathmnist.1.3.2.weight', 'heads.pathmnist.1.3.2.bias', 'heads.pathmnist.2.0.weight', 'heads.pathmnist.2.0.bias', 'heads.pathmnist.2.1.weight', 'heads.pathmnist.2.1.bias', 'heads.pathmnist.2.4.weight', 'heads.pathmnist.2.4.bias', 'heads.pathmnist.3.0.weight', 'heads.pathmnist.3.0.bias', 'heads.pathmnist.3.1.weight', 'heads.pathmnist.3.1.bias', 'heads.dermamnist.1.0.weight', 'heads.dermamnist.1.0.bias', 'heads.dermamnist.1.3.0.weight', 'heads.dermamnist.1.3.0.bias', 'heads.dermamnist.1.3.2.weight', 'heads.dermamnist.1.3.2.bias', 'heads.dermamnist.2.0.weight', 'heads.dermamnist.2.0.bias', 'heads.dermamnist.2.1.weight', 'heads.dermamnist.2.1.bias', 'heads.dermamnist.2.4.weight', 'heads.dermamnist.2.4.bias', 'heads.dermamnist.3.0.weight', 'heads.dermamnist.3.0.bias', 'heads.dermamnist.3.1.weight', 'heads.dermamnist.3.1.bias', 'heads.octmnist.1.0.weight', 'heads.octmnist.1.0.bias', 'heads.octmnist.1.3.0.weight', 'heads.octmnist.1.3.0.bias', 'heads.octmnist.1.3.2.weight', 'heads.octmnist.1.3.2.bias', 'heads.octmnist.2.0.weight', 'heads.octmnist.2.0.bias', 'heads.octmnist.2.1.weight', 'heads.octmnist.2.1.bias', 'heads.octmnist.2.4.weight', 'heads.octmnist.2.4.bias', 'heads.octmnist.3.0.weight', 'heads.octmnist.3.0.bias', 'heads.octmnist.3.1.weight', 'heads.octmnist.3.1.bias', 'heads.pneumoniamnist.1.0.weight', 'heads.pneumoniamnist.1.0.bias', 'heads.pneumoniamnist.1.3.0.weight', 'heads.pneumoniamnist.1.3.0.bias', 'heads.pneumoniamnist.1.3.2.weight', 'heads.pneumoniamnist.1.3.2.bias', 'heads.pneumoniamnist.2.0.weight', 'heads.pneumoniamnist.2.0.bias', 'heads.pneumoniamnist.2.1.weight', 'heads.pneumoniamnist.2.1.bias', 'heads.pneumoniamnist.2.4.weight', 'heads.pneumoniamnist.2.4.bias', 'heads.pneumoniamnist.3.0.weight', 'heads.pneumoniamnist.3.0.bias', 'heads.pneumoniamnist.3.1.weight', 'heads.pneumoniamnist.3.1.bias', 'heads.retinamnist.1.0.weight', 'heads.retinamnist.1.0.bias', 'heads.retinamnist.1.3.0.weight', 'heads.retinamnist.1.3.0.bias', 'heads.retinamnist.1.3.2.weight', 'heads.retinamnist.1.3.2.bias', 'heads.retinamnist.2.0.weight', 'heads.retinamnist.2.0.bias', 'heads.retinamnist.2.1.weight', 'heads.retinamnist.2.1.bias', 'heads.retinamnist.2.4.weight', 'heads.retinamnist.2.4.bias', 'heads.retinamnist.3.0.weight', 'heads.retinamnist.3.0.bias', 'heads.retinamnist.3.1.weight', 'heads.retinamnist.3.1.bias', 'heads.breastmnist.1.0.weight', 'heads.breastmnist.1.0.bias', 'heads.breastmnist.1.3.0.weight', 'heads.breastmnist.1.3.0.bias', 'heads.breastmnist.1.3.2.weight', 'heads.breastmnist.1.3.2.bias', 'heads.breastmnist.2.0.weight', 'heads.breastmnist.2.0.bias', 'heads.breastmnist.2.1.weight', 'heads.breastmnist.2.1.bias', 'heads.breastmnist.2.4.weight', 'heads.breastmnist.2.4.bias', 'heads.breastmnist.3.0.weight', 'heads.breastmnist.3.0.bias', 'heads.breastmnist.3.1.weight', 'heads.breastmnist.3.1.bias', 'heads.bloodmnist.1.0.weight', 'heads.bloodmnist.1.0.bias', 'heads.bloodmnist.1.3.0.weight', 'heads.bloodmnist.1.3.0.bias', 'heads.bloodmnist.1.3.2.weight', 'heads.bloodmnist.1.3.2.bias', 'heads.bloodmnist.2.0.weight', 'heads.bloodmnist.2.0.bias', 'heads.bloodmnist.2.1.weight', 'heads.bloodmnist.2.1.bias', 'heads.bloodmnist.2.4.weight', 'heads.bloodmnist.2.4.bias', 'heads.bloodmnist.3.0.weight', 'heads.bloodmnist.3.0.bias', 'heads.bloodmnist.3.1.weight', 'heads.bloodmnist.3.1.bias', 'heads.tissuemnist.1.0.weight', 'heads.tissuemnist.1.0.bias', 'heads.tissuemnist.1.3.0.weight', 'heads.tissuemnist.1.3.0.bias', 'heads.tissuemnist.1.3.2.weight', 'heads.tissuemnist.1.3.2.bias', 'heads.tissuemnist.2.0.weight', 'heads.tissuemnist.2.0.bias', 'heads.tissuemnist.2.1.weight', 'heads.tissuemnist.2.1.bias', 'heads.tissuemnist.2.4.weight', 'heads.tissuemnist.2.4.bias', 'heads.tissuemnist.3.0.weight', 'heads.tissuemnist.3.0.bias', 'heads.tissuemnist.3.1.weight', 'heads.tissuemnist.3.1.bias', 'heads.organamnist.1.0.weight', 'heads.organamnist.1.0.bias', 'heads.organamnist.1.3.0.weight', 'heads.organamnist.1.3.0.bias', 'heads.organamnist.1.3.2.weight', 'heads.organamnist.1.3.2.bias', 'heads.organamnist.2.0.weight', 'heads.organamnist.2.0.bias', 'heads.organamnist.2.1.weight', 'heads.organamnist.2.1.bias', 'heads.organamnist.2.4.weight', 'heads.organamnist.2.4.bias', 'heads.organamnist.3.0.weight', 'heads.organamnist.3.0.bias', 'heads.organamnist.3.1.weight', 'heads.organamnist.3.1.bias', 'heads.organcmnist.1.0.weight', 'heads.organcmnist.1.0.bias', 'heads.organcmnist.1.3.0.weight', 'heads.organcmnist.1.3.0.bias', 'heads.organcmnist.1.3.2.weight', 'heads.organcmnist.1.3.2.bias', 'heads.organcmnist.2.0.weight', 'heads.organcmnist.2.0.bias', 'heads.organcmnist.2.1.weight', 'heads.organcmnist.2.1.bias', 'heads.organcmnist.2.4.weight', 'heads.organcmnist.2.4.bias', 'heads.organcmnist.3.0.weight', 'heads.organcmnist.3.0.bias', 'heads.organcmnist.3.1.weight', 'heads.organcmnist.3.1.bias', 'heads.organsmnist.1.0.weight', 'heads.organsmnist.1.0.bias', 'heads.organsmnist.1.3.0.weight', 'heads.organsmnist.1.3.0.bias', 'heads.organsmnist.1.3.2.weight', 'heads.organsmnist.1.3.2.bias', 'heads.organsmnist.2.0.weight', 'heads.organsmnist.2.0.bias', 'heads.organsmnist.2.1.weight', 'heads.organsmnist.2.1.bias', 'heads.organsmnist.2.4.weight', 'heads.organsmnist.2.4.bias', 'heads.organsmnist.3.0.weight', 'heads.organsmnist.3.0.bias', 'heads.organsmnist.3.1.weight', 'heads.organsmnist.3.1.bias']\n",
      "Loaded checkpoint from epoch 25; missing keys: [], unexpected keys: []\n",
      "Model1 weight: 0.4806, Model2 weight: 0.5194\n"
     ]
    }
   ],
   "source": [
    "# Instantiate two models with the same architecture\n",
    "model1 = MedMNISTMultiTaskModel(backbone_name='convnext_tiny', pretrained=True)\n",
    "model2 = MedMNISTMultiTaskModel(backbone_name='convnext_tiny', pretrained=True)\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "\n",
    "# Load checkpoints for each model\n",
    "model1, metric1 = load_checkpoint(checkpoint_path1, model1)\n",
    "model2, metric2 = load_checkpoint(checkpoint_path2, model2)\n",
    "\n",
    "# Set models to evaluation mode\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "# Compute ensemble weights based on validation metrics (e.g., F1 scores)\n",
    "total_metric = metric1 + metric2 + 1e-6\n",
    "w1 = metric1 / total_metric\n",
    "w2 = metric2 / total_metric\n",
    "print(f\"Model1 weight: {w1:.4f}, Model2 weight: {w2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7d68be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T12:11:45.250759Z",
     "iopub.status.busy": "2025-02-22T12:11:45.250499Z",
     "iopub.status.idle": "2025-02-22T12:13:37.050132Z",
     "shell.execute_reply": "2025-02-22T12:13:37.049143Z"
    },
    "papermill": {
     "duration": 111.805156,
     "end_time": "2025-02-22T12:13:37.051638",
     "exception": false,
     "start_time": "2025-02-22T12:11:45.246482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: pathmnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: pathmnist: 100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: dermamnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: dermamnist: 100%|██████████| 8/8 [00:02<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: octmnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: octmnist: 100%|██████████| 4/4 [00:01<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: pneumoniamnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: pneumoniamnist: 100%|██████████| 3/3 [00:00<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: retinamnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: retinamnist: 100%|██████████| 2/2 [00:00<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: breastmnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: breastmnist: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: bloodmnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: bloodmnist: 100%|██████████| 14/14 [00:03<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: tissuemnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: tissuemnist: 100%|██████████| 185/185 [00:52<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: organamnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: organamnist: 100%|██████████| 70/70 [00:20<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: organcmnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: organcmnist: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: organsmnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task: organsmnist: 100%|██████████| 35/35 [00:10<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total submission rows: 96941\n",
      "Submission file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission_rows = []\n",
    "global_id = 0\n",
    "\n",
    "# Use torch.no_grad() and the new AMP syntax.\n",
    "with torch.no_grad(), torch.amp.autocast('cuda'):\n",
    "    for task in DATASETS:\n",
    "        print(f\"Processing task: {task}\")\n",
    "        loader = test_dataloaders[task]\n",
    "        image_idx = 0\n",
    "        task_idx = DATASETS.index(task)\n",
    "        for images in tqdm(loader, desc=f\"Task: {task}\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            batch_size_current = images.size(0)\n",
    "            # Create a task_ids tensor for the batch\n",
    "            task_ids = torch.full((batch_size_current,), task_idx, dtype=torch.long, device=device)\n",
    "            \n",
    "            # Get outputs (logits) from both models\n",
    "            outputs1 = model1(images, task_ids=task_ids)\n",
    "            outputs2 = model2(images, task_ids=task_ids)\n",
    "            \n",
    "            num_cls = model1.task_outputs[task]  # same for both models\n",
    "            # Convert outputs to softmax probabilities over the task-specific number of classes\n",
    "            probs1 = torch.softmax(outputs1[:, :num_cls], dim=1)\n",
    "            probs2 = torch.softmax(outputs2[:, :num_cls], dim=1)\n",
    "            \n",
    "            # Compute weighted average of probabilities\n",
    "            avg_probs = w1 * probs1 + w2 * probs2\n",
    "            \n",
    "            # Final prediction is the argmax of the averaged probabilities\n",
    "            preds = avg_probs.argmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            # Record predictions\n",
    "            for pred in preds:\n",
    "                submission_rows.append([global_id, image_idx, task, int(pred)])\n",
    "                global_id += 1\n",
    "                image_idx += 1\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows, columns=[\"id\", \"id_image_in_task\", \"task_name\", \"label\"])\n",
    "print(\"Total submission rows:\", len(submission_df))\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc3bdd",
   "metadata": {
    "papermill": {
     "duration": 0.021225,
     "end_time": "2025-02-22T12:13:37.094866",
     "exception": false,
     "start_time": "2025-02-22T12:13:37.073641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final Summary\n",
    "In this notebook, we built a weighted ensemble of two pre‑trained MedMNIST multi‑task models:\n",
    "- **Model Definition:** We use a custom model (with a ConvNeXt backbone and task‑specific heads) exactly as used during training.\n",
    "- **Checkpoint Loading:** Two checkpoints are loaded with `strict=False`, and their validation metrics are used to compute ensemble weights.\n",
    "- **Test Data Preparation:** We load NPZ test files for each task and create DataLoaders.\n",
    "- **Weighted Inference:** For each batch, we compute softmax probabilities from both models, weight them according to their validation performance, and average to obtain the final predictions.\n",
    "- **Submission File:** The predictions are saved to a CSV file in the required format.\n",
    "\n",
    "This weighted ensemble approach gives more influence to the better‑performing model and is expected to yield competitive results on the leaderboard. Adjust the weighting scheme and hyperparameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e2e10",
   "metadata": {
    "papermill": {
     "duration": 0.020682,
     "end_time": "2025-02-22T12:13:37.136502",
     "exception": false,
     "start_time": "2025-02-22T12:13:37.115820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9915460,
     "sourceId": 86864,
     "sourceType": "competition"
    },
    {
     "sourceId": 216397634,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 223375151,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 158.849121,
   "end_time": "2025-02-22T12:13:39.814646",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-22T12:11:00.965525",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f2c6c58b67041809399903cb6afeb22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "21a0ce1bacbf42f9a22d423a98fc1a97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "455ccf529f6f4ab2b6a53938d939ee91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a3f28d116bd45a7a5020d9d97c2e4da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fd5e24ea31a5480d92d835df9ec31971",
       "placeholder": "​",
       "style": "IPY_MODEL_81d325cf2c3b4fcd98141a7278e96e2a",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "81d325cf2c3b4fcd98141a7278e96e2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8745517438804381b7dcf59de22353eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9106f7de4a154ca7992006a6a2169081": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e9cc6ce7ce494c87bb1cb585027e9cc3",
       "max": 114374272.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0f2c6c58b67041809399903cb6afeb22",
       "tabbable": null,
       "tooltip": null,
       "value": 114374272.0
      }
     },
     "b1f584015e704dedaf576f7bb903fa82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_455ccf529f6f4ab2b6a53938d939ee91",
       "placeholder": "​",
       "style": "IPY_MODEL_21a0ce1bacbf42f9a22d423a98fc1a97",
       "tabbable": null,
       "tooltip": null,
       "value": " 114M/114M [00:00&lt;00:00, 238MB/s]"
      }
     },
     "b2013e823fc641648c7361dfb0de31ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7a3f28d116bd45a7a5020d9d97c2e4da",
        "IPY_MODEL_9106f7de4a154ca7992006a6a2169081",
        "IPY_MODEL_b1f584015e704dedaf576f7bb903fa82"
       ],
       "layout": "IPY_MODEL_8745517438804381b7dcf59de22353eb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e9cc6ce7ce494c87bb1cb585027e9cc3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd5e24ea31a5480d92d835df9ec31971": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
